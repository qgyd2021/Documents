## 奇异值分解

https://www.zhihu.com/question/263722514/answer/272977924



### 推导

设矩阵 $A_{m \times n}$ 是 $m$ 行 $n$ 列矩阵, $x$ 是 $n$ 行 $1$ 列的单位向量, $y$ 是 $m$ 行 $1$ 列的单位向量, 即:  $|x| = |y| = 1$. 

建立以下等式: 

$$\begin{aligned} y = Ax \end{aligned}$$ 



$$\begin{aligned} y = \left[
\begin{matrix} y_{1} \\ y_{2} \\ \cdots \\ y_{m} \end{matrix}
\right] \end{aligned}$$ 

$$\begin{aligned} x = \left[
\begin{matrix} x_{1} \\ x_{2} \\ \cdots \\ x_{n} \end{matrix}
\right] \end{aligned}$$ 

$$\begin{aligned} A = \left[
\begin{matrix} a_{11} & a_{12} & \cdots & a_{1n} \\ a_{21} & a_{22} & \cdots & a_{2n} \\ \cdots & \cdots & \cdots & \cdots \\ a_{m1} & a_{m2} & \cdots & a_{mn} \end{matrix}
\right] \end{aligned}$$ 



我们知道, 当等式数大于未知数个数时 $(m > n)$, 方程组无解; 等于未知数个数时 $(m = n)$, 方程组有唯一解; 小于未知数个数时 $(m < n)$, 方程组有无穷个解. 

一般情况, 当方程组无解时, 可通过最小化平方误差, 求最近似解; 有无穷个解时, 可通过最小化未知数范数, 求解. 



此处, 虽然有 $|x| = 1$, $|y| = 1$ 单位向量 (范数为一) 的限制, 但仍然不能保证等式数与未知数个数相等. 

因此, 我们追加 **最大小内积** 作为附加条件. 建立目标方程, 如下: 

$$\begin{aligned} \max{f(x, y)} = y^{\top} A x \end{aligned}$$ 



根据拉格朗日乘子法: 

$$\begin{aligned} f(x, y) = & y^{\top} A x \\ g(x, y) = & x^{\top} x + y^{\top} y - 2 = 0 \end{aligned}$$ 

等价于求下式的最大值: 

$$\begin{aligned} F(x, y, \lambda) = f(x, y) + \lambda g_(x, y) \end{aligned}$$ 



求导数为 $0$ 的极值点: 

$$\begin{aligned} \frac{\partial{F}}{\partial{x}} = & y^{\top} A + \lambda x^{\top}  = 0 \end{aligned}$$ 

$$\begin{aligned} \frac{\partial{F}}{\partial{y}} = & (Ax)^{\top} + \lambda y^{\top} \\ = & x^{\top} A^{\top} + \lambda y^{\top} = 0 \end{aligned}$$ 



$$\begin{aligned} y^{\top} A + \lambda x^{\top} = & \left[
\begin{matrix} y_{1} & y_{2} & \cdots & y_{m} \end{matrix}
\right] \cdot \left[
\begin{matrix} a_{11} & a_{12} & \cdots & a_{1n} \\ a_{21} & a_{22} & \cdots & a_{2n} \\ \cdots & \cdots & \cdots & \cdots \\ a_{m1} & a_{m2} & \cdots & a_{mn} \end{matrix}
\right] + \lambda \left[
\begin{matrix} x_{1} & x_{2} & \cdots & x_{n} \end{matrix}
\right] = \left[
\begin{matrix} 0 & 0 & \cdots & 0 \end{matrix}
\right]_{1 \times n} \\ A^{\top} y + \lambda x = & \left[
\begin{matrix} a_{11} & a_{21} & \cdots & a_{m1} \\ a_{12} & a_{22} & \cdots & a_{m2} \\ \cdots & \cdots & \cdots & \cdots \\ a_{1n} & a_{2n} & \cdots & a_{mn} \end{matrix}
\right] \cdot \left[
\begin{matrix} y_{1} \\ y_{2} \\ \cdots \\ y_{m} \end{matrix}
\right] + \lambda \left[
\begin{matrix} x_{1} \\ x_{2} \\ \cdots \\ x_{n} \end{matrix}
\right] = \left[
\begin{matrix} 0 \\ 0 \\ \cdots \\ 0 \end{matrix}
\right]_{n \times 1} \end{aligned}$$ 



$$\begin{aligned} x^{\top} A^{\top} + \lambda y^{\top} = & \left[
\begin{matrix} x_{1} & x_{2} & \cdots & x_{n} \end{matrix}
\right] \cdot \left[
\begin{matrix} a_{11} & a_{21} & \cdots & a_{m1} \\ a_{12} & a_{22} & \cdots & a_{m2} \\ \cdots & \cdots & \cdots & \cdots \\ a_{1n} & a_{2n} & \cdots & a_{mn} \end{matrix}
\right] + \lambda \left[
\begin{matrix} y_{1} & y_{2} & \cdots & y_{m} \end{matrix}
\right] = \left[
\begin{matrix} 0 & 0 & \cdots & 0 \end{matrix}
\right]_{1 \times m} \\ A x + \lambda y = & \left[
\begin{matrix} a_{11} & a_{12} & \cdots & a_{1n} \\ a_{21} & a_{22} & \cdots & a_{2n} \\ \cdots & \cdots & \cdots & \cdots \\ a_{m1} & a_{m2} & \cdots & a_{mn} \end{matrix}
\right] \cdot \left[
\begin{matrix} x_{1} \\ x_{2} \\ \cdots \\ x_{n} \end{matrix}
\right] + \lambda \left[
\begin{matrix} y_{1} \\ y_{2} \\ \cdots \\ y_{m} \end{matrix}
\right] = \left[
\begin{matrix} 0 \\ 0 \\ \cdots \\ 0 \end{matrix}
\right]_{m \times 1} \end{aligned}$$ 



将上面两个等式合并到一个矩阵运算中: 

$$\begin{aligned} \left[
\begin{matrix} a_{11} & a_{12} & \cdots & a_{1n} & \lambda & 0 & \cdots & 0 \\ a_{21} & a_{22} & \cdots & a_{2n} & 0 & \lambda & \cdots & 0 \\ \cdots & \cdots & \cdots & \cdots & \cdots & \cdots & \cdots & \cdots \\ a_{m1} & a_{m2} & \cdots & a_{mn} & 0 & 0 & \cdots & \lambda \\ \lambda & 0 & \cdots & 0 & a_{11} & a_{21} & \cdots & a_{m1} \\ 0 & \lambda & \cdots & 0 & a_{12} & a_{22} & \cdots & a_{m2} \\ \cdots & \cdots & \cdots & \cdots & \cdots & \cdots & \cdots & \cdots \\ 0 & 0 & \cdots & \lambda & a_{1n} & a_{2n} & \cdots & a_{mn} \end{matrix}
\right]_{m \times n, m \times m \\ n \times n , n \times m} \cdot \left[
\begin{matrix} x_{1} \\ x_{2} \\ \cdots \\ x_{n} \\ y_{1} \\ y_{2} \\ \cdots \\ y_{m} \end{matrix}
\right]_{n \times 1 \\ m \times 1} = \left[
\begin{matrix} 0 \\ 0 \\ \cdots \\ 0 \\ 0 \\ 0 \\ \cdots \\ 0 \end{matrix}
\right]_{m \times 1 \\ n \times 1} \end{aligned}$$ 

$$\begin{aligned} \left[
\begin{matrix} A_{m \times n} & \lambda I_{m \times m} \\ \lambda I_{n \times n} & A_{m \times n}^{\top} \end{matrix}
\right] \cdot \left[
\begin{matrix} x_{n \times 1} \\ y_{m \times 1} \end{matrix}
\right] = \left[
\begin{matrix} 0_{m \times 1} \\ 0_{n \times 1} \end{matrix}
\right] \end{aligned}$$ 



求上式的非零解, 则其系数矩阵必然奇异, 其**行列式为 **$0$: 

$$\begin{aligned} \text{det} \left( \left[
\begin{matrix} A_{m \times n} & \lambda I_{m \times m} \\ \lambda I_{n \times n} & A_{m \times n}^{\top} \end{matrix}
\right]  \right) = 0 \end{aligned}$$ 

求解上式, 得到 $\lambda$ 的取值 (应该有多个值). 然后再求出各 $\lambda$ 对应的解: 

$$\begin{aligned} \left[
\begin{matrix} x_{n \times 1} \\ y_{m \times 1} \end{matrix}
\right] = \left[
\begin{matrix} u \\ v \end{matrix}
\right] \end{aligned}$$ 

其中 $u$, $v$ 都是单位向量. 



又有, 从导数为 $0$ 的下式推导: 

$$\begin{aligned} \frac{\partial{F}}{\partial{x}} = & y^{\top} A + \lambda x^{\top}  = 0 \end{aligned}$$ 

有: 

$$\begin{aligned} y^{\top} A + \lambda x^{\top} = & 0 \\ y^{\top} A = & - \lambda x^{\top} \\ v^{\top} A = & - \lambda u^{\top} \end{aligned}$$ 



根据等式 $v^{\top} A = - \lambda u^{\top}$ , 以及 **行列式为 0** 的等式. 

我们可以从 $u$, $v$ 的解组成单位正交基向量: 

$$\begin{aligned} U = \left[
\begin{matrix} u_{1} & u_{2} & \cdots & u_{n} \end{matrix}
\right] = \left[
\begin{matrix} u_{11} & u_{21} & \cdots & u_{n1} \\ u_{12} & u_{22} & \cdots & u_{n2} \\ \cdots & \cdots & \cdots & \cdots \\ u_{1n} & u_{2n} & \cdots & u_{nn} \end{matrix}
\right] \end{aligned} $$ 

$$\begin{aligned} V = \left[
\begin{matrix} v_{1} & v_{2} & \cdots & v_{m} \end{matrix}
\right] = \left[
\begin{matrix} v_{11} & v_{21} & \cdots & v_{m1} \\ v_{12} & v_{22} & \cdots & v_{m2} \\ \cdots & \cdots & \cdots & \cdots \\ v_{1m} & v_{2m} & \cdots & v_{mm} \end{matrix}
\right] \end{aligned}$$ 

**注意**: 从行列式为 0 求解出一部分基向量 $u$, $v$, 再根据已知基向量, 推出其它尚未确定的基向量. 由于推出未知基向量时, 其正负方向不确定. 因此, 最后可生成的**基向组 $U$, $V$ 不唯一**, 且不同基向量组之间只是部分基向量的正负方向不同. 



推导: 

$$\begin{aligned} V^{\top} A = & \Lambda U^{\top} \\ \left[
\begin{matrix} v_{11} & v_{12} & \cdots & v_{1m} \end{matrix}
\right] \cdot \left[
\begin{matrix} a_{11} & a_{12} & \cdots & a_{1n} \\ a_{21} & a_{22} & \cdots & a_{2n} \\ \cdots & \cdots & \cdots & \cdots \\ a_{m1} & a_{m2} & \cdots & a_{mn} \end{matrix}
\right] = & \lambda_{1} \times \left[
\begin{matrix} u_{11} & u_{12} & \cdots & u_{1n} \end{matrix}
\right] \\ \left[
\begin{matrix} 1 & 0 & \cdots & 0 \\ 0 & 1 & \cdots & 0 \\ \cdots & \cdots & \cdots & \cdots \\ 0 & 0 & \cdots & 1 \end{matrix}
\right] \cdot \left[
\begin{matrix} v_{11} & v_{12} & \cdots & v_{1m} \\ v_{21} & v_{22} & \cdots & v_{2m} \\ \cdots & \cdots & \cdots & \cdots \\ v_{m1} & v_{m2} & \cdots & v_{mm} \end{matrix}
\right] \cdot \left[
\begin{matrix} a_{11} & a_{12} & \cdots & a_{1n} \\ a_{21} & a_{22} & \cdots & a_{2n} \\ \cdots & \cdots & \cdots & \cdots \\ a_{m1} & a_{m2} & \cdots & a_{mn} \end{matrix}
\right] = & \lambda_{1} \times \left[
\begin{matrix} 1 & 0 & \cdots & 0 \\ 0 & 1 & \cdots & 0 \\ \cdots & \cdots & \cdots & \cdots \\ 0 & 0 & \cdots & 1 \end{matrix}
\right] \cdot \left[
\begin{matrix} u_{11} & u_{12} & \cdots & u_{1n} \\ u_{21} & u_{22} & \cdots & u_{2n} \\ \cdots & \cdots & \cdots & \cdots \\ u_{n1} & u_{n2} & \cdots & u_{nn} \end{matrix}
\right] \\ \left[
\begin{matrix} 1 & 0 & \cdots & 0 \\ 0 & 1 & \cdots & 0 \\ \cdots & \cdots & \cdots & \cdots \\ 0 & 0 & \cdots & 1 \end{matrix}
\right] \cdot \left[
\begin{matrix} v_{11} & v_{12} & \cdots & v_{1m} \\ v_{21} & v_{22} & \cdots & v_{2m} \\ \cdots & \cdots & \cdots & \cdots \\ v_{m1} & v_{m2} & \cdots & v_{mm} \end{matrix}
\right] \cdot \left[
\begin{matrix} a_{11} & a_{12} & \cdots & a_{1n} \\ a_{21} & a_{22} & \cdots & a_{2n} \\ \cdots & \cdots & \cdots & \cdots \\ a_{m1} & a_{m2} & \cdots & a_{mn} \end{matrix}
\right] \cdot \left[
\begin{matrix} u_{11} & u_{21} & \cdots & u_{n1} \\ u_{12} & u_{22} & \cdots & u_{n2} \\ \cdots & \cdots & \cdots & \cdots \\ u_{1n} & u_{2n} & \cdots & u_{nn} \end{matrix}
\right] = & \lambda_{1} \times \left[
\begin{matrix} 1 & 0 & \cdots & 0 \\ 0 & 1 & \cdots & 0 \\ \cdots & \cdots & \cdots & \cdots \\ 0 & 0 & \cdots & 1 \end{matrix}
\right] \\ \left[
\begin{matrix} 1 & 0 & \cdots & 0 \\ 0 & 1 & \cdots & 0 \\ \cdots & \cdots & \cdots & \cdots \\ 0 & 0 & \cdots & 1 \end{matrix}
\right]_{m \times m} \cdot \hat{A} = & \left[ \begin{matrix} \lambda_{1} \\ \lambda_{2} \\ \cdots \\ \lambda_{m} \end{matrix} \right] \times \left[
\begin{matrix} 1 & 0 & \cdots & 0 \\ 0 & 1 & \cdots & 0 \\ \cdots & \cdots & \cdots & \cdots \\ 0 & 0 & \cdots & 1 \end{matrix}
\right]_{n \times n} \end{aligned}$$ 

上式如果成立, 则 $\hat{A}$ 中必须满足: 第一行第一列为 $\lambda_{1}$, 其它都为 $0$; 第二行第列为 $\lambda_{2}$, 其它都为 $0$; $\cdots$

因此有: 

$$\begin{aligned} \Sigma = \left[
\begin{matrix} \lambda_{1} & 0 & \cdots & 0 & \cdots & 0 \\ 0 & \lambda_{2} & \cdots & 0 & \cdots & 0 \\ \cdots & \cdots & \cdots & \cdots & \cdots & \cdots \\ 0 & 0 & \cdots & \lambda_{m} & \cdots & 0 \end{matrix}
\right]_{m \times n} \quad \text{注: 非 0 } \lambda \text{ 数可能小于 m} \end{aligned}$$ 



有: 

$$\begin{aligned} V^{\top} A U = & \Sigma \\ \left[
\begin{matrix} v_{11} & v_{12} & \cdots & v_{1m} \\ v_{21} & v_{22} & \cdots & v_{2m} \\ \cdots & \cdots & \cdots & \cdots \\ v_{m1} & v_{m2} & \cdots & v_{mm} \end{matrix}
\right] \cdot \left[
\begin{matrix} a_{11} & a_{12} & \cdots & a_{1n} \\ a_{21} & a_{22} & \cdots & a_{2n} \\ \cdots & \cdots & \cdots & \cdots \\ a_{m1} & a_{m2} & \cdots & a_{mn} \end{matrix}
\right] \cdot \left[
\begin{matrix} u_{11} & u_{21} & \cdots & u_{n1} \\ u_{12} & u_{22} & \cdots & u_{n2} \\ \cdots & \cdots & \cdots & \cdots \\ u_{1n} & u_{2n} & \cdots & u_{nn} \end{matrix}
\right] = & \left[
\begin{matrix} \lambda_{1} & 0 & \cdots & 0 & \cdots & 0 \\ 0 & \lambda_{2} & \cdots & 0 & \cdots & 0 \\ \cdots & \cdots & \cdots & \cdots & \cdots & \cdots \\ 0 & 0 & \cdots & \lambda_{m} & \cdots & 0 \end{matrix}
\right]_{m \times n} \end{aligned}$$ 



$$\begin{aligned} A = & V \Sigma U^{\top} \\ \left[
\begin{matrix} a_{11} & a_{12} & \cdots & a_{1n} \\ a_{21} & a_{22} & \cdots & a_{2n} \\ \cdots & \cdots & \cdots & \cdots \\ a_{m1} & a_{m2} & \cdots & a_{mn} \end{matrix}
\right] = & \left[
\begin{matrix} v_{11} & v_{21} & \cdots & v_{m1} \\ v_{12} & v_{22} & \cdots & v_{m2} \\ \cdots & \cdots & \cdots & \cdots \\ v_{1m} & v_{2m} & \cdots & v_{mm} \end{matrix}
\right] \cdot \left[
\begin{matrix} \lambda_{1} & 0 & \cdots & 0 & \cdots & 0 \\ 0 & \lambda_{2} & \cdots & 0 & \cdots & 0 \\ \cdots & \cdots & \cdots & \cdots & \cdots & \cdots \\ 0 & 0 & \cdots & \lambda_{m} & \cdots & 0 \end{matrix}
\right]_{m \times n} \cdot \left[
\begin{matrix} u_{11} & u_{12} & \cdots & u_{1n} \\ u_{21} & u_{22} & \cdots & u_{2n} \\ \cdots & \cdots & \cdots & \cdots \\ u_{n1} & u_{n2} & \cdots & u_{nn} \end{matrix}
\right] \end{aligned}$$ 



### 结论

**奇异值分解**: 任意矩阵都可分解为 $A = V \Sigma U^{\top}$ 的形式 (**不唯一**). 



从等式中可以看出, $A$ 矩阵对应的线性变换可理解为: 

1. 将 $n$ 维向量分解到其 $n$ 维基向量组上. 
2. 通过特征值 $\lambda$ 对其分量进行缩放, 并舍弃部分维度 ($n - m$ 个维度) 的值. 
3. 向量在各基向量上的投影值经过缩放后, 在 $m$ 维空间中, 通过基向量相加, 还原向量. 



### 奇异值分解

从推导中, 我们发现了任意矩阵的奇异值分解的存在, 此处我们提出一种更方便的奇异值分解的计算方法. 



从方程组: 

$$\begin{aligned} A = & V \Sigma U^{\top} \end{aligned}$$ 

有: 

$$\begin{aligned} A A^{\top} = & V \Sigma U^{\top} U \Sigma^{\top} V^{\top} \\ = & V \Sigma I \Sigma^{\top} V^{\top} \\ = & V \Sigma \Sigma^{\top} V^{\top} \\ = & \left[
\begin{matrix} v_{11} & v_{21} & \cdots & v_{m1} \\ v_{12} & v_{22} & \cdots & v_{m2} \\ \cdots & \cdots & \cdots & \cdots \\ v_{1m} & v_{2m} & \cdots & v_{mm} \end{matrix}
\right] \cdot \left[
\begin{matrix} \lambda_{1} & 0 & \cdots & 0 & \cdots & 0 \\ 0 & \lambda_{2} & \cdots & 0 & \cdots & 0 \\ \cdots & \cdots & \cdots & \cdots & \cdots & \cdots \\ 0 & 0 & \cdots & \lambda_{m} & \cdots & 0 \end{matrix}
\right]_{m \times n} \cdot \left[
\begin{matrix} \lambda_{1} & 0 & \cdots & 0 \\ 0 & \lambda_{2} & \cdots & 0 \\ \cdots & \cdots & \cdots & \cdots \\ 0 & 0 & \cdots & \lambda_{m} \\ \cdots & \cdots & \cdots & \cdots \\ 0 & 0 & \cdots & 0 \end{matrix}
\right]_{n \times m} \cdot \left[
\begin{matrix} v_{11} & v_{12} & \cdots & v_{1m} \\ v_{21} & v_{22} & \cdots & v_{2m} \\ \cdots & \cdots & \cdots & \cdots \\ v_{m2} & v_{m2} & \cdots & v_{mm} \end{matrix}
\right] \\ = & \left[
\begin{matrix} v_{11} & v_{21} & \cdots & v_{m1} \\ v_{12} & v_{22} & \cdots & v_{m2} \\ \cdots & \cdots & \cdots & \cdots \\ v_{1m} & v_{2m} & \cdots & v_{mm} \end{matrix}
\right] \cdot \left[
\begin{matrix} \lambda_{1}^{2} & 0 & \cdots & 0 \\ 0 & \lambda_{2}^{2} & \cdots & 0 \\ \cdots & \cdots & \cdots & \cdots \\ 0 & 0 & \cdots & \lambda_{m}^{2} \end{matrix}
\right]_{m \times m} \cdot \left[
\begin{matrix} v_{11} & v_{12} & \cdots & v_{1m} \\ v_{21} & v_{22} & \cdots & v_{2m} \\ \cdots & \cdots & \cdots & \cdots \\ v_{m2} & v_{m2} & \cdots & v_{mm} \end{matrix}
\right]  \end{aligned}$$ 



又有: 

$$\begin{aligned} A^{\top} A = & U \Sigma^{\top} V^{\top} V \Sigma U^{\top} \\ = & U \Sigma^{\top} I \Sigma U^{\top} \\ = & U \Sigma^{\top} \Sigma U^{\top} \\ = &   \left[
\begin{matrix} u_{11} & u_{21} & \cdots & u_{n1} \\ u_{12} & u_{22} & \cdots & u_{n2} \\ \cdots & \cdots & \cdots & \cdots \\ u_{1n} & u_{2n} & \cdots & u_{nn} \end{matrix}
\right] \cdot \left[
\begin{matrix} \lambda_{1} & 0 & \cdots & 0 \\ 0 & \lambda_{2} & \cdots & 0 \\ \cdots & \cdots & \cdots & \cdots \\ 0 & 0 & \cdots & \lambda_{m} \\ \cdots & \cdots & \cdots & \cdots \\ 0 & 0 & \cdots & 0 \end{matrix}
\right]_{n \times m} \cdot \left[
\begin{matrix} \lambda_{1} & 0 & \cdots & 0 & \cdots & 0 \\ 0 & \lambda_{2} & \cdots & 0 & \cdots & 0 \\ \cdots & \cdots & \cdots & \cdots & \cdots & \cdots \\ 0 & 0 & \cdots & \lambda_{m} & \cdots & 0 \end{matrix}
\right]_{m \times n} \cdot \left[
\begin{matrix} u_{11} & u_{12} & \cdots & u_{1n} \\ u_{21} & u_{22} & \cdots & u_{2n} \\ \cdots & \cdots & \cdots & \cdots \\ u_{n1} & u_{n2} & \cdots & u_{nn} \end{matrix}
\right] \\ = & \left[
\begin{matrix} u_{11} & u_{21} & \cdots & u_{n1} \\ u_{12} & u_{22} & \cdots & u_{n2} \\ \cdots & \cdots & \cdots & \cdots \\ u_{1n} & u_{2n} & \cdots & u_{nn} \end{matrix}
\right] \cdot \left[
\begin{matrix} \lambda_{1}^{2} & 0 & \cdots & 0 & \cdots & 0 \\ 0 & \lambda_{2}^{2} & \cdots & 0 & \cdots & 0 \\ \cdots & \cdots & \cdots & \cdots & \cdots & \cdots \\ 0 & 0 & \cdots & \lambda_{m}^{2} & \cdots & 0 \\ \cdots & \cdots & \cdots & \cdots & \cdots & 0 \\ 0 & 0 & \cdots & 0 & \cdots & 0 \end{matrix}
\right]_{n \times n} \cdot \left[
\begin{matrix} u_{11} & u_{12} & \cdots & u_{1n} \\ u_{21} & u_{22} & \cdots & u_{2n} \\ \cdots & \cdots & \cdots & \cdots \\ u_{n1} & u_{n2} & \cdots & u_{nn} \end{matrix}
\right] \end{aligned}$$ 







### 应用



##### 1. 信息压缩

有: 

$$\begin{aligned} A = & V \Lambda U^{-1} \\ = & V \Lambda U^{\top} \\ = & \left[
\begin{matrix} v_{11} & v_{21} & \cdots & v_{m1} \\ v_{12} & v_{22} & \cdots & v_{m2} \\ \cdots & \cdots & \cdots & \cdots \\ v_{1m} & v_{2m} & \cdots & v_{mm} \end{matrix}
\right] \cdot \left[
\begin{matrix} \lambda_{1} & 0 & \cdots & 0 & \cdots & 0 \\ 0 & \lambda_{2} & \cdots & 0 & \cdots & 0 \\ \cdots & \cdots & \cdots & \cdots & \cdots & \cdots \\ 0 & 0 & \cdots & \lambda_{m} & \cdots & 0 \end{matrix}
\right]_{m \times n} \cdot \left[
\begin{matrix} u_{11} & u_{12} & \cdots & u_{1m} & \cdots & u_{1n} \\ u_{21} & u_{22} & \cdots & u_{2m} & \cdots & u_{2n} \\ \cdots & \cdots & \cdots & \cdots & \cdots & \cdots \\ u_{m1} & u_{m2} & \cdots & u_{mm} & \cdots & u_{2n} \\ \cdots & \cdots & \cdots & \cdots & \cdots & \cdots \\ u_{n1} & u_{n2} & \cdots & u_{nm} & \cdots & u_{nn} \end{matrix}
\right] \end{aligned}$$ 

通过上式可以看出, $Ax$ 运算, 相当于是将 $x$ 向量投影到 $n$ 维基向量组上, 再分别缩放 (乘以特征值) 再在 $m$ 维空间基向量组上相加. 这样的变换过程. 



设有任意向量 $X_{n \times 1}$, 

1. 将该向量 $X_{n \times 1}$ 映射到 $n$ 维基向量组上. 
2. 通过特征值对分解后的 $X_{n \times 1}$ 进行缩放 (缩放里, 相当于也舍弃了 $(n-m)$ 个维度). 
3. 向量在各基向量上的投影值经过缩放后, 再在 $m$ 维空间的基向量组上相加, 还原向量. 



$$\begin{aligned} AX = & V \Lambda U^{\top} X \\ = & \left[
\begin{matrix} v_{11} & v_{21} & \cdots & v_{m1} \\ v_{12} & v_{22} & \cdots & v_{m2} \\ \cdots & \cdots & \cdots & \cdots \\ v_{1m} & v_{2m} & \cdots & v_{mm} \end{matrix}
\right] \cdot \left[
\begin{matrix} \lambda_{1} & 0 & \cdots & 0 & \cdots & 0 \\ 0 & \lambda_{2} & \cdots & 0 & \cdots & 0 \\ \cdots & \cdots & \cdots & \cdots & \cdots & \cdots \\ 0 & 0 & \cdots & \lambda_{m} & \cdots & 0 \end{matrix}
\right]_{m \times n} \cdot \left[
\begin{matrix} u_{11} & u_{12} & \cdots & u_{1m} & \cdots & u_{1n} \\ u_{21} & u_{22} & \cdots & u_{2m} & \cdots & u_{2n} \\ \cdots & \cdots & \cdots & \cdots & \cdots & \cdots \\ u_{m1} & u_{m2} & \cdots & u_{mm} & \cdots & u_{mn} \\ \cdots & \cdots & \cdots & \cdots & \cdots & \cdots \\ u_{n1} & u_{n2} & \cdots & u_{nm} & \cdots & u_{nn} \end{matrix}
\right] \cdot \left[
\begin{matrix} x_{1} \\ x_{2} \\ \cdots \\ x_{m} \\ \cdots \\ x_{n} \end{matrix}
\right] \\ = & \left[
\begin{matrix} v_{11} & v_{21} & \cdots & v_{m1} \\ v_{12} & v_{22} & \cdots & v_{m2} \\ \cdots & \cdots & \cdots & \cdots \\ v_{1m} & v_{2m} & \cdots & v_{mm} \end{matrix}
\right] \cdot \left[
\begin{matrix} \lambda_{1} & 0 & \cdots & 0 & \cdots & 0 \\ 0 & \lambda_{2} & \cdots & 0 & \cdots & 0 \\ \cdots & \cdots & \cdots & \cdots & \cdots & \cdots \\ 0 & 0 & \cdots & \lambda_{m} & \cdots & 0 \end{matrix}
\right]_{m \times n} \cdot \left[
\begin{matrix} u_{11} & u_{12} & \cdots & u_{1m} & \cdots & u_{1n} \\ u_{21} & u_{22} & \cdots & u_{2m} & \cdots & u_{2n} \\ \cdots & \cdots & \cdots & \cdots & \cdots & \cdots \\ u_{m1} & u_{m2} & \cdots & u_{mm} & \cdots & u_{mn} \\ \cdots & \cdots & \cdots & \cdots & \cdots & \cdots \\ u_{n1} & u_{n2} & \cdots & u_{nm} & \cdots & u_{nn} \end{matrix}
\right] \cdot \left[
\begin{matrix} u_{11} & u_{21} & \cdots & u_{m1} & \cdots & u_{n1} \\ u_{12} & u_{22} & \cdots & u_{m2} & \cdots & u_{n2} \\ \cdots & \cdots & \cdots & \cdots & \cdots & \cdots \\ u_{1m} & u_{2m} & \cdots & u_{mm} & \cdots & u_{nm} \\ \cdots & \cdots & \cdots & \cdots & \cdots & \cdots \\ u_{1n} & u_{2n} & \cdots & u_{mn} & \cdots & u_{nn} \end{matrix}
\right] \cdot \left[
\begin{matrix} \gamma_{1} \\ \gamma_{2} \\ \cdots \\ \gamma_{m} \\ \cdots \\ \gamma_{n} \end{matrix}
\right] \\ = & \left[
\begin{matrix} v_{11} & v_{21} & \cdots & v_{m1} \\ v_{12} & v_{22} & \cdots & v_{m2} \\ \cdots & \cdots & \cdots & \cdots \\ v_{1m} & v_{2m} & \cdots & v_{mm} \end{matrix}
\right] \cdot \left[
\begin{matrix} \lambda_{1} & 0 & \cdots & 0 & \cdots & 0 \\ 0 & \lambda_{2} & \cdots & 0 & \cdots & 0 \\ \cdots & \cdots & \cdots & \cdots & \cdots & \cdots \\ 0 & 0 & \cdots & \lambda_{m} & \cdots & 0 \end{matrix}
\right]_{m \times n} \cdot \left[ \begin{matrix} 1 & 0 & \cdots & 0 & \cdots & 0 \\ 0 & 1 & \cdots & 0 & \cdots & 0 \\ \cdots & \cdots & \cdots & \cdots & \cdots & \cdots \\ 0 & 0 & \cdots & 1 & \cdots & 0 \\ \cdots & \cdots & \cdots & \cdots & \cdots & \cdots \\ 0 & 0 & \cdots & 0 & \cdots & 1 \end{matrix} \right] \cdot \left[
\begin{matrix}  \gamma_{1} \\ \gamma_{2} \\ \cdots \\ \gamma_{m} \\ \cdots \\ \gamma_{n} \end{matrix}
\right] \\ = & \left[
\begin{matrix} v_{11} & v_{21} & \cdots & v_{m1} \\ v_{12} & v_{22} & \cdots & v_{m2} \\ \cdots & \cdots & \cdots & \cdots \\ v_{1m} & v_{2m} & \cdots & v_{mm} \end{matrix}
\right] \cdot \left[
\begin{matrix} \lambda_{1} & 0 & \cdots & 0 & \cdots & 0 \\ 0 & \lambda_{2} & \cdots & 0 & \cdots & 0 \\ \cdots & \cdots & \cdots & \cdots & \cdots & \cdots \\ 0 & 0 & \cdots & \lambda_{m} & \cdots & 0 \end{matrix}
\right]_{m \times n} \cdot \left[
\begin{matrix} \gamma_{1} \\ \gamma_{2} \\ \cdots \\ \gamma_{m} \\ \cdots \\ \gamma_{n} \end{matrix}
\right] \\ = & \left[
\begin{matrix} v_{11} & v_{21} & \cdots & v_{m1} \\ v_{12} & v_{22} & \cdots & v_{m2} \\ \cdots & \cdots & \cdots & \cdots \\ v_{1m} & v_{2m} & \cdots & v_{mm} \end{matrix}
\right] \cdot \left[
\begin{matrix} \lambda_{1} \gamma_{1} \\ \lambda_{2} \gamma_{2} \\ \cdots \\ \lambda_{m} \gamma_{m} \end{matrix}
\right]_{m \times n} \\ = & \left[
\begin{matrix} \lambda_{1} \gamma_{1} v_{11} + \lambda_{2} \gamma_{2} v_{21} + \cdots + \lambda_{m} \gamma_{m} v_{m1} \\ \lambda_{1} \gamma_{1} v_{12} + \lambda_{2} \gamma_{2} v_{22} + \cdots + \lambda_{m} \gamma_{m} v_{m2} \\ \cdots \\ \lambda_{1} \gamma_{1} v_{1m} + \lambda_{2} \gamma_{2} v_{2m} + \cdots + \lambda_{m} \gamma_{m} v_{mm} \end{matrix}
\right] \end{aligned}$$ 



计算第 $i$ 个基向量 $v_{i}$ 对结果的影响: 

$$\begin{aligned} \text{square\_error} = & \left[ \begin{matrix} \lambda_{i} \gamma_{i} v_{i1} & \lambda_{i} \gamma_{i} v_{i2} & \cdots & \lambda_{i} \gamma_{i} v_{im} \end{matrix} \right] \cdot \left[
\begin{matrix} \lambda_{i} \gamma_{i} v_{i1} \\ \lambda_{i} \gamma_{i} v_{i2} \\ \cdots \\ \lambda_{i} \gamma_{i} v_{im} \end{matrix}
\right] \\ = & \lambda_{i}^{2} \times \gamma_{i}^{2} \times \left[ \begin{matrix}  v_{i1} & v_{i2} & \cdots & v_{in} \end{matrix} \right] \cdot \left[
\begin{matrix} v_{i1} \\ v_{i2} \\ \cdots \\ v_{in} \end{matrix}
\right] \\ = & \lambda_{i}^{2} \times \gamma_{i}^{2} \times 1 \end{aligned}$$ 

上式, 对于非特定向量, $\gamma_{i}^{2}$ 的期望 $E(\gamma_{i}^{2}) = C$  是常量. 因此, 特征向量对 **平方误差** 的影响是由特征值大小决定的. 

在实践中, 可舍弃特征值较小的特征向量, 以实现数据压缩. 



备注: 

1. 基向量的正负方向并不影响 $\text{square\_error}$ 平方误差的结果. 因此虽然奇异值分解不唯一, 但在此处没有影响. 
2. 从上面的推导中, 还可以发现, $u_{m+1,i}$ 到 $u_{n,i}$ 的向量对最终的结果, 并没有影响. 可见, 当矩阵 $A_{m \times n}$ 将向量从高维映射到低维里, 奇异值分解相当于获得了 $n$ 空间与 $m$ 维空间之间相关的那一组基向量. 
3. 当矩阵 $A_{m \times n}$ 的秩 $\text{Rank (A)} < m$ 时, 特征值矩阵 $\Sigma_{m \times n}$ 中必定有一部分特征值为 $0$. 





**信息压缩实例**: 

令 $I$ 表示单位向量. 

$$\begin{aligned} A = & A I \\ = & V \Lambda U^{\top} I \\ = & \left[
\begin{matrix} v_{11} & v_{21} & \cdots & v_{m1} \\ v_{12} & v_{22} & \cdots & v_{m2} \\ \cdots & \cdots & \cdots & \cdots \\ v_{1m} & v_{2m} & \cdots & v_{mm} \end{matrix}
\right] \cdot \left[
\begin{matrix} \lambda_{1} & 0 & \cdots & 0 & \cdots & 0 \\ 0 & \lambda_{2} & \cdots & 0 & \cdots & 0 \\ \cdots & \cdots & \cdots & \cdots & \cdots & \cdots \\ 0 & 0 & \cdots & \lambda_{m} & \cdots & 0 \end{matrix}
\right]_{m \times n} \cdot \left[
\begin{matrix} u_{11} & u_{12} & \cdots & u_{1m} & \cdots & u_{1n} \\ u_{21} & u_{22} & \cdots & u_{2m} & \cdots & u_{2n} \\ \cdots & \cdots & \cdots & \cdots & \cdots & \cdots \\ u_{m1} & u_{m2} & \cdots & u_{mm} & \cdots & u_{mn} \\ \cdots & \cdots & \cdots & \cdots & \cdots & \cdots \\ u_{n1} & u_{n2} & \cdots & u_{nm} & \cdots & u_{nn} \end{matrix}
\right] \cdot \left[
\begin{matrix} 1 & 0 & \cdots & 0 & \cdots & 0 \\ 0 & 1 & \cdots & 0 & \cdots & 0 \\ \cdots & \cdots & \cdots & \cdots & \cdots & \cdots \\ 0 & 0 & \cdots & 1 & \cdots & 0 \\ \cdots & \cdots & \cdots & \cdots & \cdots & \cdots \\ 0 & 0 & \cdots & 0 & \cdots & 1 \end{matrix}
\right]  \end{aligned}$$ 

根据前面的推导, 当我们在此处位留全部的单位基向量时, 可以完全还原矩阵 $A$. 

当舍弃值最小的 $\lambda$ 时, 可得到与原矩阵 $A$ 相比 $\text{square\_error}$ 平方误差最小的近似矩阵 $A^{'}$. 



















































